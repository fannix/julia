{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling MLDatasets [eb30cadb-4394-5ae3-aed4-317e484a6458]\n",
      "└ @ Base loading.jl:1242\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: onehotbatch, argmax, crossentropy, throttle, @epochs\n",
    "using Base.Iterators: repeated, partition\n",
    "using MLDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion is done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.23137254901960785 0.06274509803921569 … 0.7058823529411764 0.6941176470588235; 0.16862745098039217 0.0 … 0.6784313725490196 0.6588235294117647; … ; 0.596078431372549 0.4666666666666667 … 0.3803921568627451 0.592156862745098; 0.580392156862745 0.4784313725490196 … 0.3254901960784314 0.4823529411764706]\n",
       "\n",
       "[0.24313725490196078 0.0784313725490196 … 0.5450980392156862 0.5647058823529412; 0.1803921568627451 0.0 … 0.4823529411764706 0.5058823529411764; … ; 0.49019607843137253 0.3254901960784314 … 0.24313725490196078 0.4627450980392157; 0.48627450980392156 0.3411764705882353 … 0.20784313725490194 0.3607843137254902]\n",
       "\n",
       "[0.24705882352941178 0.0784313725490196 … 0.3764705882352941 0.4549019607843137; 0.1764705882352941 0.0 … 0.16470588235294117 0.3686274509803922; … ; 0.4 0.19607843137254902 … 0.13333333333333333 0.32941176470588235; 0.403921568627451 0.22352941176470587 … 0.13333333333333333 0.2823529411764706]\n",
       "\n",
       "[0.6039215686274509 0.5490196078431373 … 0.6470588235294118 0.6392156862745098; 0.49411764705882355 0.5686274509803921 … 0.611764705882353 0.6196078431372549; … ; 0.3411764705882353 0.30196078431372547 … 0.4823529411764706 0.5607843137254902; 0.30980392156862746 0.2784313725490196 … 0.5137254901960784 0.5607843137254902]\n",
       "\n",
       "[0.6941176470588235 0.6274509803921569 … 0.6039215686274509 0.580392156862745; 0.5372549019607843 0.6 … 0.596078431372549 0.580392156862745; … ; 0.3529411764705882 0.3137254901960784 … 0.44705882352941173 0.5254901960784314; 0.3176470588235294 0.28627450980392155 … 0.4745098039215686 0.5215686274509804]\n",
       "\n",
       "[0.7333333333333333 0.6627450980392157 … 0.5019607843137255 0.47058823529411764; 0.5333333333333333 0.6039215686274509 … 0.5098039215686274 0.4784313725490196; … ; 0.2784313725490196 0.24313725490196078 … 0.47058823529411764 0.5568627450980392; 0.27450980392156865 0.2392156862745098 … 0.5137254901960784 0.5647058823529412]\n",
       "\n",
       "[1.0 1.0 … 0.43529411764705883 0.4156862745098039; 0.9921568627450981 1.0 … 0.40784313725490196 0.38823529411764707; … ; 0.9921568627450981 1.0 … 0.27450980392156865 0.30980392156862746; 0.9921568627450981 1.0 … 0.3058823529411765 0.3137254901960784]\n",
       "\n",
       "[1.0 1.0 … 0.4627450980392157 0.44313725490196076; 0.9921568627450981 1.0 … 0.43529411764705883 0.4156862745098039; … ; 0.9921568627450981 1.0 … 0.2980392156862745 0.3333333333333333; 0.9921568627450981 1.0 … 0.32941176470588235 0.33725490196078434]\n",
       "\n",
       "[1.0 1.0 … 0.43137254901960786 0.4117647058823529; 0.9921568627450981 1.0 … 0.40784313725490196 0.38431372549019605; … ; 0.9921568627450981 1.0 … 0.29411764705882354 0.3254901960784314; 0.9921568627450981 1.0 … 0.32156862745098036 0.32941176470588235]\n",
       "\n",
       "...\n",
       "\n",
       "[0.13725490196078433 0.22352941176470587 … 0.2392156862745098 0.17254901960784313; 0.1568627450980392 0.17254901960784313 … 0.21568627450980393 0.1803921568627451; … ; 0.30980392156862746 0.5529411764705883 … 0.06666666666666667 0.08235294117647059; 0.34901960784313724 0.4549019607843137 … 0.027450980392156862 0.047058823529411764]\n",
       "\n",
       "[0.6980392156862745 0.7137254901960784 … 0.26666666666666666 0.2196078431372549; 0.6901960784313725 0.7215686274509804 … 0.27450980392156865 0.2588235294117647; … ; 0.5764705882352941 0.6941176470588235 … 0.13725490196078433 0.16862745098039217; 0.580392156862745 0.5843137254901961 … 0.09019607843137255 0.12156862745098039]\n",
       "\n",
       "[0.9215686274509803 0.9176470588235294 … 0.29411764705882354 0.28627450980392155; 0.9372549019607843 0.9803921568627451 … 0.33725490196078434 0.34509803921568627; … ; 0.7725490196078432 0.807843137254902 … 0.20784313725490194 0.2588235294117647; 0.7411764705882353 0.6862745098039216 … 0.12549019607843137 0.19607843137254902]\n",
       "\n",
       "[0.7411764705882353 0.7607843137254902 … 0.7764705882352941 0.7764705882352941; 0.7294117647058823 0.7490196078431373 … 0.7411764705882353 0.7411764705882353; … ; 0.6745098039215687 0.6705882352941176 … 0.6862745098039216 0.7686274509803921; 0.6627450980392157 0.6549019607843137 … 0.6862745098039216 0.7647058823529411]\n",
       "\n",
       "[0.8274509803921568 0.8235294117647058 … 0.7450980392156863 0.7411764705882353; 0.8156862745098039 0.8117647058823529 … 0.7098039215686275 0.7098039215686275; … ; 0.7607843137254902 0.7490196078431373 … 0.6627450980392157 0.7411764705882353; 0.7607843137254902 0.7450980392156863 … 0.6627450980392157 0.7450980392156863]\n",
       "\n",
       "[0.9411764705882353 0.9372549019607843 … 0.6666666666666666 0.6784313725490196; 0.9254901960784314 0.9254901960784314 … 0.6235294117647059 0.6352941176470588; … ; 0.8705882352941177 0.8549019607843137 … 0.611764705882353 0.6705882352941176; 0.8627450980392157 0.8470588235294118 … 0.6039215686274509 0.6705882352941176]\n",
       "\n",
       "[0.8980392156862745 0.8705882352941177 … 0.5372549019607843 0.4784313725490196; 0.9254901960784314 0.9372549019607843 … 0.5098039215686274 0.4627450980392157; … ; 0.8666666666666667 0.8901960784313725 … 0.792156862745098 0.6431372549019607; 0.8705882352941177 0.8235294117647058 … 0.8313725490196078 0.6392156862745098]\n",
       "\n",
       "[0.8980392156862745 0.8666666666666667 … 0.5176470588235293 0.4666666666666667; 0.9294117647058824 0.9372549019607843 … 0.4980392156862745 0.4549019607843137; … ; 0.8745098039215686 0.8941176470588235 … 0.788235294117647 0.6431372549019607; 0.8745098039215686 0.8274509803921568 … 0.8274509803921568 0.6392156862745098]\n",
       "\n",
       "[0.9372549019607843 0.8980392156862745 … 0.49411764705882355 0.44705882352941173; 0.9686274509803922 0.9764705882352941 … 0.47058823529411764 0.43137254901960786; … ; 0.9176470588235294 0.9333333333333333 … 0.7764705882352941 0.6352941176470588; 0.9137254901960784 0.8627450980392157 … 0.8117647058823529 0.6313725490196078], Bool[0 0 … 0 0; 0 0 … 1 1; … ; 0 0 … 0 0; 0 1 … 0 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "# load CIFAR-10 training set\n",
    "trainX, trainY = CIFAR10.traindata()\n",
    "testX,  testY  = CIFAR10.testdata()\n",
    "\n",
    "# MLDatasets returns UInt8 thus convert it to Float64\n",
    "trainX = Array{Float64}(trainX)\n",
    "testX = Array{Float64}(testX)\n",
    "println(\"conversion is done\")\n",
    "\n",
    "# construct one-hot vectors from labels\n",
    "trainY = onehotbatch(trainY, 0:9)\n",
    "testY = onehotbatch(testY, 0:9)\n",
    "\n",
    "train = (trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This program has requested access to the data dependency CIFAR10.\n",
      "which is not currently installed. It can be installed automatically, and you will not see this message again.\n",
      "\n",
      "Dataset: The CIFAR-10 dataset\n",
      "Authors: Alex Krizhevsky, Vinod Nair, Geoffrey Hinton\n",
      "Website: https://www.cs.toronto.edu/~kriz/cifar.html\n",
      "Reference: https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf\n",
      "\n",
      "[Krizhevsky, 2009]\n",
      "    Alex Krizhevsky.\n",
      "    \"Learning Multiple Layers of Features from Tiny Images\",\n",
      "    Tech Report, 2009.\n",
      "\n",
      "The CIFAR-10 dataset is a labeled subsets of the 80\n",
      "million tiny images dataset. It consists of 60000\n",
      "32x32 colour images in 10 classes, with 6000 images\n",
      "per class.\n",
      "\n",
      "The compressed archive file that contains the\n",
      "complete dataset is available for download at the\n",
      "offical website linked above; specifically the binary\n",
      "version for C programs. Note that using the data\n",
      "responsibly and respecting copyright remains your\n",
      "responsibility. The authors of CIFAR-10 aren't really\n",
      "explicit about any terms of use, so please read the\n",
      "website to make sure you want to download the\n",
      "dataset.\n",
      "\n",
      "\n",
      "\n",
      "Do you want to download the dataset from https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz to \"/home/xmeng/.julia/datadeps/CIFAR10\"?\n",
      "[y/n]\n",
      "stdin> y\n",
      "conversion is done\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching Array{Any,N} where N(::Int64)\nClosest candidates are:\n  Array{Any,N} where N(!Matched::UndefInitializer, !Matched::Int64) where T at boot.jl:418\n  Array{Any,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64) where T at boot.jl:419\n  Array{Any,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64, !Matched::Int64) where T at boot.jl:420\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Array{Any,N} where N(::Int64)\nClosest candidates are:\n  Array{Any,N} where N(!Matched::UndefInitializer, !Matched::Int64) where T at boot.jl:418\n  Array{Any,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64) where T at boot.jl:419\n  Array{Any,N} where N(!Matched::UndefInitializer, !Matched::Int64, !Matched::Int64, !Matched::Int64) where T at boot.jl:420\n  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[3]:17"
     ]
    }
   ],
   "source": [
    "# TODO convert below to list comprehension\n",
    "# TODO shuffle\n",
    "# split training set into batches\n",
    "# train_data contains whole data in batches\n",
    "train_data = Array{Any}(div(50000, BATCH_SIZE))\n",
    "for i = 0:div(50000, BATCH_SIZE) - 1\n",
    "    train_data[i+1] = train[1][:,:,:, 1 + i*BATCH_SIZE:(i+1)*BATCH_SIZE],\n",
    "                      train[2][:, 1 + i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "end\n",
    "\n",
    "println(\"data is ready to be learnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "  Conv((3,3), 3=>16, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  Conv((2,2), 16=>8, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  x -> reshape(x, :, size(x, 4)),\n",
    "  Dense(8*7*7 , 10), softmax)\n",
    "\n",
    "m(train_data[1][1])\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "accuracy(x, y) = mean(argmax(m(x)) .== argmax(y))\n",
    "evalcb = throttle(() -> @show(accuracy(testX, testY)), 10)\n",
    "opt = ADAM(params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to train\n",
    "\n",
    "# Flux.train!() runs for 1 epoch, default. \n",
    "# Change 15 to train for different epochs using @epochs macro\n",
    "@epochs 15 Flux.train!(loss, train, opt, cb = evalcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
